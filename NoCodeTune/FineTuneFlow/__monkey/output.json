{job_name: matt_gray_3, parent_job_name: null, base_job_name: full_train, filenames_and_version: matt_gray_.csv:1, args: {train_type: full_train, training_args: {max_steps: 20, save_steps: 10, num_train_epochs: 5, base_model_name: EleutherAI/pythia-410m, dataset_path: files/corymuscara2.csv, update_data_to_twitter_agent: true, learning_rate: 5e-05, metric_for_best_model: eval_loss, disable_tqdm: true, eval_steps: 1, warmup_steps: 1, per_device_eval_batch_size: 8, evaluation_strategy: steps, logging_strategy: steps, optim: adafactor, gradient_accumulation_steps: 4, gradient_checkpointing: false}, peft_args: {finetuned_model_paths: [EleutherAI/pythia-410m], first_peft_train: true, existing_peft_model_path: , first_train_step: 1, update_model_step: 1}, lora_configs: {r: 32, lora_alpha: 64, target_modules: [query_key_value], lora_dropout: 0.1, bias: none, task_type: CAUSAL_LM}}}
